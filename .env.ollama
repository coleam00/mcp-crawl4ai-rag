# =================================================================
#  OLLAMA CONFIGURATION TEMPLATE
# =================================================================
# Copy this file to .env and adjust the Supabase settings
# This template is pre-configured for Qwen3-Embedding with Ollama

# --- Server Settings ---
HOST=0.0.0.0
PORT=8051
TRANSPORT=sse

# --- Ollama Configuration ---
# Local Ollama endpoints (adjust for Docker if needed)
CHAT_MODEL_API_BASE=http://localhost:11434/v1  # Use http://host.docker.internal:11434/v1 in Docker
CHAT_MODEL_API_KEY=ollama  # Required but ignored by Ollama
EMBEDDING_MODEL_API_BASE=http://localhost:11434/v1  # Use http://host.docker.internal:11434/v1 in Docker
EMBEDDING_MODEL_API_KEY=ollama  # Required but ignored by Ollama

# --- Model Selection ---
# Recommended: Use 8B for production, 0.6B for development
CHAT_MODEL=qwen3:latest
EMBEDDING_MODEL=dengcao/Qwen3-Embedding-8B  # or dengcao/Qwen3-Embedding-0.6B
RERANKING_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# --- Vector Database (Supabase) ---
# REQUIRED: Set these to your Supabase project values
SUPABASE_URL=your_supabase_project_url
SUPABASE_SERVICE_KEY=your_supabase_service_key

# --- Knowledge Graph Database (Neo4j) ---
# Optional: Only needed if USE_KNOWLEDGE_GRAPH=true
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# --- RAG Strategy Flags ---
USE_CONTEXTUAL_EMBEDDINGS=false
USE_HYBRID_SEARCH=false
USE_AGENTIC_RAG=false
USE_RERANKING=false
USE_KNOWLEDGE_GRAPH=false

# --- Advanced Configuration ---
MAX_CRAWL_DEPTH=3
MAX_CONCURRENT_CRAWLS=10
CHUNK_SIZE=5000
MIN_CODE_BLOCK_LENGTH=1000
DEFAULT_MATCH_COUNT=5

# --- Embedding Configuration ---
# Optimal dimensions for Qwen3-Embedding models:
# 0.6B model: 1024 or less
# 8B model: 1024-4096
EMBEDDING_DIMENSIONS=1024

# --- Concurrency Settings ---
MAX_WORKERS_SUMMARY=10
MAX_WORKERS_CONTEXT=10
MAX_WORKERS_SOURCE_SUMMARY=5
SUPABASE_BATCH_SIZE=20