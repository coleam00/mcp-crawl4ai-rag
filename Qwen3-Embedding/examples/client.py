#!/usr/bin/env python3
"""
Cliente de exemplo para Qwen3-Embedding API
Demonstra como usar a API compat√≠vel com OpenAI
"""

import openai
import numpy as np
import time
import json
from typing import List, Optional
import argparse
import sys


class Qwen3EmbeddingClient:
    """Cliente para API Qwen3-Embedding"""
    
    def __init__(self, base_url: str = "http://localhost:8000/v1", api_key: str = "EMPTY"):
        """
        Inicializar cliente
        
        Args:
            base_url: URL base da API
            api_key: Chave da API (EMPTY para vLLM)
        """
        self.client = openai.OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        self.base_url = base_url
        
    def get_models(self) -> List[str]:
        """Listar modelos dispon√≠veis"""
        try:
            models = self.client.models.list()
            return [model.id for model in models.data]
        except Exception as e:
            print(f"Erro ao listar modelos: {e}")
            return []
    
    def embed_text(
        self, 
        text: str, 
        model: str = "Qwen/Qwen3-Embedding-0.6B",
        dimensions: Optional[int] = None
    ) -> List[float]:
        """
        Gerar embedding para um texto
        
        Args:
            text: Texto para embedding
            model: Nome do modelo
            dimensions: Dimens√µes customizadas (opcional)
            
        Returns:
            Lista de floats representando o embedding
        """
        try:
            kwargs = {
                "model": model,
                "input": [text],
                "encoding_format": "float"
            }
            
            if dimensions:
                kwargs["dimensions"] = dimensions
                
            response = self.client.embeddings.create(**kwargs)
            return response.data[0].embedding
            
        except Exception as e:
            print(f"Erro ao gerar embedding: {e}")
            return []
    
    def embed_batch(
        self, 
        texts: List[str], 
        model: str = "Qwen/Qwen3-Embedding-0.6B",
        dimensions: Optional[int] = None
    ) -> List[List[float]]:
        """
        Gerar embeddings para m√∫ltiplos textos
        
        Args:
            texts: Lista de textos
            model: Nome do modelo
            dimensions: Dimens√µes customizadas (opcional)
            
        Returns:
            Lista de embeddings
        """
        try:
            kwargs = {
                "model": model,
                "input": texts,
                "encoding_format": "float"
            }
            
            if dimensions:
                kwargs["dimensions"] = dimensions
                
            response = self.client.embeddings.create(**kwargs)
            return [item.embedding for item in response.data]
            
        except Exception as e:
            print(f"Erro ao gerar embeddings em lote: {e}")
            return []
    
    def calculate_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:
        """
        Calcular similaridade coseno entre dois embeddings
        
        Args:
            embedding1: Primeiro embedding
            embedding2: Segundo embedding
            
        Returns:
            Similaridade coseno (-1 a 1)
        """
        vec1 = np.array(embedding1)
        vec2 = np.array(embedding2)
        
        # Normalizar vetores
        vec1_norm = vec1 / np.linalg.norm(vec1)
        vec2_norm = vec2 / np.linalg.norm(vec2)
        
        # Calcular similaridade coseno
        similarity = np.dot(vec1_norm, vec2_norm)
        return float(similarity)
    
    def benchmark_dimensions(self, text: str = "Teste de benchmark", model: str = "Qwen/Qwen3-Embedding-0.6B"):
        """Fazer benchmark de diferentes dimens√µes"""
        dimensions = [128, 256, 512, 768, 1024]
        
        print(f"üî¨ Benchmark de dimens√µes para: '{text}'")
        print("-" * 60)
        
        for dim in dimensions:
            start_time = time.time()
            embedding = self.embed_text(text, model, dimensions=dim)
            end_time = time.time()
            
            if embedding:
                duration = end_time - start_time
                print(f"Dimens√£o {dim:4d}: {duration:.3f}s - Tamanho: {len(embedding)}")
            else:
                print(f"Dimens√£o {dim:4d}: ERRO")
    
    def semantic_search_demo(self):
        """Demonstra√ß√£o de busca sem√¢ntica"""
        # Documentos de exemplo
        documents = [
            "O gato subiu no telhado da casa",
            "Python √© uma linguagem de programa√ß√£o",
            "Machine learning √© uma √°rea da intelig√™ncia artificial",
            "O cachorro correu pelo jardim",
            "Deep learning usa redes neurais artificiais",
            "JavaScript √© usado para desenvolvimento web"
        ]
        
        # Query de busca
        query = "intelig√™ncia artificial e programa√ß√£o"
        
        print(f"üîç Busca sem√¢ntica para: '{query}'")
        print("-" * 60)
        
        # Gerar embeddings
        print("Gerando embeddings...")
        query_embedding = self.embed_text(query)
        doc_embeddings = self.embed_batch(documents)
        
        if not query_embedding or not doc_embeddings:
            print("Erro ao gerar embeddings!")
            return
        
        # Calcular similaridades
        similarities = []
        for i, doc_embedding in enumerate(doc_embeddings):
            similarity = self.calculate_similarity(query_embedding, doc_embedding)
            similarities.append((i, similarity, documents[i]))
        
        # Ordenar por similaridade
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # Mostrar resultados
        print("\nResultados (ordenados por relev√¢ncia):")
        for rank, (doc_idx, similarity, document) in enumerate(similarities, 1):
            print(f"{rank}. [{similarity:.3f}] {document}")


def main():
    parser = argparse.ArgumentParser(description="Cliente Qwen3-Embedding")
    parser.add_argument("--url", default="http://localhost:8000/v1", help="URL da API")
    parser.add_argument("--model", default="Qwen/Qwen3-Embedding-0.6B", help="Nome do modelo")
    parser.add_argument("--text", help="Texto para embedding")
    parser.add_argument("--dimensions", type=int, help="Dimens√µes customizadas")
    parser.add_argument("--benchmark", action="store_true", help="Executar benchmark")
    parser.add_argument("--demo", action="store_true", help="Executar demo de busca sem√¢ntica")
    parser.add_argument("--models", action="store_true", help="Listar modelos dispon√≠veis")
    
    args = parser.parse_args()
    
    # Criar cliente
    client = Qwen3EmbeddingClient(base_url=args.url)
    
    try:
        # Listar modelos
        if args.models:
            print("üìã Modelos dispon√≠veis:")
            models = client.get_models()
            for model in models:
                print(f"  - {model}")
            return
        
        # Benchmark
        if args.benchmark:
            client.benchmark_dimensions(model=args.model)
            return
        
        # Demo de busca sem√¢ntica
        if args.demo:
            client.semantic_search_demo()
            return
        
        # Embedding de texto espec√≠fico
        if args.text:
            print(f"üìù Gerando embedding para: '{args.text}'")
            
            start_time = time.time()
            embedding = client.embed_text(args.text, args.model, args.dimensions)
            end_time = time.time()
            
            if embedding:
                print(f"‚úÖ Embedding gerado em {end_time - start_time:.3f}s")
                print(f"   Dimens√µes: {len(embedding)}")
                print(f"   Primeiros 10 valores: {embedding[:10]}")
                
                # Salvar em arquivo se solicitado
                output_file = f"embedding_{int(time.time())}.json"
                with open(output_file, 'w') as f:
                    json.dump({
                        "text": args.text,
                        "model": args.model,
                        "dimensions": len(embedding),
                        "embedding": embedding,
                        "timestamp": time.time()
                    }, f, indent=2)
                print(f"   Salvo em: {output_file}")
            else:
                print("‚ùå Erro ao gerar embedding")
                sys.exit(1)
            return
        
        # Se nenhuma a√ß√£o espec√≠fica, mostrar menu interativo
        print("ü§ñ Cliente Qwen3-Embedding Interativo")
        print("=" * 50)
        
        while True:
            print("\nOp√ß√µes:")
            print("1. Gerar embedding de texto")
            print("2. Busca sem√¢ntica (demo)")
            print("3. Benchmark de dimens√µes")
            print("4. Listar modelos")
            print("5. Sair")
            
            choice = input("\nEscolha uma op√ß√£o (1-5): ").strip()
            
            if choice == "1":
                text = input("Digite o texto: ").strip()
                if text:
                    dims = input("Dimens√µes (Enter para padr√£o): ").strip()
                    dimensions = int(dims) if dims.isdigit() else None
                    
                    embedding = client.embed_text(text, args.model, dimensions)
                    if embedding:
                        print(f"‚úÖ Embedding: {len(embedding)} dimens√µes")
                        print(f"   Amostra: {embedding[:5]}...")
                    else:
                        print("‚ùå Erro ao gerar embedding")
            
            elif choice == "2":
                client.semantic_search_demo()
            
            elif choice == "3":
                text = input("Texto para benchmark (Enter para padr√£o): ").strip()
                if not text:
                    text = "Teste de benchmark"
                client.benchmark_dimensions(text, args.model)
            
            elif choice == "4":
                models = client.get_models()
                print("üìã Modelos:")
                for model in models:
                    print(f"  - {model}")
            
            elif choice == "5":
                print("üëã At√© logo!")
                break
            
            else:
                print("‚ùå Op√ß√£o inv√°lida!")
                
    except KeyboardInterrupt:
        print("\nüëã Interrompido pelo usu√°rio")
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 