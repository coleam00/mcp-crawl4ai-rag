# =============================================================================
# MCP CRAWL4AI RAG CONFIGURATION
# =============================================================================

# -----------------------------------------------------------------------------
# TRANSPORT SETTINGS
# -----------------------------------------------------------------------------
# The transport for the MCP server - either 'sse' or 'stdio'
TRANSPORT=sse

# Host to bind to if using sse as the transport (leave empty if using stdio)
HOST=0.0.0.0

# Port to listen on if using sse as the transport (leave empty if using stdio)
PORT=8051

# =============================================================================
# AI PROVIDER CONFIGURATION
# Choose between dual-provider mode (NEW) or single-provider mode (LEGACY)
# =============================================================================

# -----------------------------------------------------------------------------
# DUAL-PROVIDER MODE (Recommended - Mix providers for optimal cost/performance)
# -----------------------------------------------------------------------------
# Uncomment ONE of the configurations below:

# üí∞ COST-OPTIMIZED: OpenAI embeddings (quality) + DeepSeek completions (cheap)
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small
# LLM_PROVIDER=deepseek
# LLM_MODEL=deepseek-chat
# OPENAI_API_KEY=sk-your_openai_key_here
# DEEPSEEK_API_KEY=your_deepseek_key_here

# üÜì FREE TIER: Gemini for both (generous free quotas)
# EMBEDDING_PROVIDER=gemini
# EMBEDDING_MODEL=text-embedding-004
# LLM_PROVIDER=gemini
# LLM_MODEL=gemini-1.5-flash
# GEMINI_API_KEY=your_gemini_key_here

# üîí COMPLETELY LOCAL: Ollama for everything (no data leaves your machine)
# EMBEDDING_PROVIDER=ollama
# EMBEDDING_MODEL=nomic-embed-text
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.2
# OLLAMA_BASE_URL=http://localhost:11434/v1

# üè¢ ENTERPRISE: OpenAI embeddings + Anthropic completions (highest quality)
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-large
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-5-sonnet-20241022
# OPENAI_API_KEY=sk-your_openai_key_here
# ANTHROPIC_API_KEY=your_anthropic_key_here

# üåê OPENROUTER ACCESS: OpenAI embeddings + OpenRouter LLMs (diverse model access)
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small
# LLM_PROVIDER=openrouter
# LLM_MODEL=anthropic/claude-3-5-haiku
# OPENAI_API_KEY=sk-your_openai_key_here
# OPENROUTER_API_KEY=your_openrouter_key_here

# -----------------------------------------------------------------------------
# SINGLE-PROVIDER MODE (Backward Compatible - One provider for both)
# -----------------------------------------------------------------------------
# Uncomment ONE of the options below:

# OpenAI (default)
# AI_PROVIDER=openai
# MODEL_CHOICE=gpt-4o-mini
# OPENAI_API_KEY=sk-your_openai_key_here

# Gemini (free tier friendly)
# AI_PROVIDER=gemini
# MODEL_CHOICE=gemini-1.5-flash
# GEMINI_API_KEY=your_gemini_key_here

# Ollama (completely local)
# AI_PROVIDER=ollama
# MODEL_CHOICE=llama3.2
# OLLAMA_BASE_URL=http://localhost:11434/v1
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text
# OLLAMA_COMPLETION_MODEL=llama3.2

# DeepSeek (cheap completions only - no embeddings)
# AI_PROVIDER=deepseek
# MODEL_CHOICE=deepseek-chat
# DEEPSEEK_API_KEY=your_deepseek_key_here

# Anthropic (completions only - no embeddings)
# AI_PROVIDER=anthropic
# MODEL_CHOICE=claude-3-5-haiku-20241022
# ANTHROPIC_API_KEY=your_anthropic_key_here

# =============================================================================
# API KEYS (Add only the ones you need based on your provider choice)
# =============================================================================

# OpenAI API Key
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# Google Gemini API Key  
# Get from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=

# DeepSeek API Key
# Get from: https://platform.deepseek.com/api_keys
DEEPSEEK_API_KEY=

# Anthropic API Key
# Get from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=

# OpenRouter API Key
# Get from: https://openrouter.ai/keys
OPENROUTER_API_KEY=

# Ollama Base URL (if running Ollama locally)
OLLAMA_BASE_URL=http://localhost:11434/v1

# =============================================================================
# RAG STRATEGIES (Advanced Features)
# =============================================================================
# Set these to "true" or "false" - all default to "false"

# Enhances embeddings with contextual information for better retrieval
USE_CONTEXTUAL_EMBEDDINGS=false

# Combines vector similarity search with keyword search for better results  
USE_HYBRID_SEARCH=false

# Enables code example extraction, storage, and specialized code search
USE_AGENTIC_RAG=false

# Applies cross-encoder reranking to improve search result relevance
USE_RERANKING=false

# =============================================================================
# SUPABASE CONFIGURATION (Required for RAG functionality)
# =============================================================================

# Your Supabase project URL
# Get from: https://supabase.com/dashboard/project/<project-id>/settings/api
SUPABASE_URL=

# Your Supabase service key (service_role secret)  
# Get from: https://supabase.com/dashboard/project/<project-id>/settings/api
SUPABASE_SERVICE_KEY=

# =============================================================================
# CONFIGURATION EXAMPLES BY USE CASE
# =============================================================================

# üéØ FOR DEVELOPMENT/TESTING:
# Use Gemini (free tier) or Ollama (local) to avoid costs
# EMBEDDING_PROVIDER=gemini, LLM_PROVIDER=gemini, GEMINI_API_KEY=...

# üíº FOR PRODUCTION (COST-CONSCIOUS):
# Use OpenAI embeddings + DeepSeek completions for best cost/performance ratio
# EMBEDDING_PROVIDER=openai, LLM_PROVIDER=deepseek, OPENAI_API_KEY=..., DEEPSEEK_API_KEY=...

# üè¢ FOR ENTERPRISE/HIGH-QUALITY:
# Use OpenAI embeddings + Anthropic completions for maximum quality
# EMBEDDING_PROVIDER=openai, LLM_PROVIDER=anthropic, OPENAI_API_KEY=..., ANTHROPIC_API_KEY=...

# üîí FOR PRIVACY/SECURITY:
# Use Ollama for completely local deployment
# EMBEDDING_PROVIDER=ollama, LLM_PROVIDER=ollama, OLLAMA_BASE_URL=http://localhost:11434/v1

# üåê FOR MODEL DIVERSITY:
# Use OpenAI embeddings + OpenRouter for access to many different LLMs
# EMBEDDING_PROVIDER=openai, LLM_PROVIDER=openrouter, OPENAI_API_KEY=..., OPENROUTER_API_KEY=... 